{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the tutorial from this [link](http://mnemstudio.org/path-finding-q-learning-tutorial.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "\n",
    "# defines the reward/connection graph\n",
    "r = np.array([[-1, -1, -1, -1, 0, -1],\n",
    "              [-1, -1, -1, 0, -1, 100],\n",
    "              [-1, -1, -1, 0, -1, -1],\n",
    "              [-1, 0, 0, -1, 0, -1],\n",
    "              [0, -1, -1, 0, -1, 100],\n",
    "              [-1, 0, -1, -1, 0, 100]]).astype(\"float32\")\n",
    "\n",
    "q = np.zeros_like(r)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_q(state, next_state, action, alpha, gamma):\n",
    "    rsa = r[state, action]\n",
    "    qsa = q[state, action]\n",
    "    new_q = qsa + alpha * (rsa + gamma * max(q[next_state, :]) - qsa)\n",
    "    q[state, action] = new_q\n",
    "    # renormalize row to be between 0 and 1\n",
    "    rn = q[state][q[state] > 0] / np.sum(q[state][q[state] > 0])\n",
    "    q[state][q[state] > 0] = rn\n",
    "    return r[state, action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greedy traversal for starting state 0\n",
      "0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0\n",
      "\n",
      "greedy traversal for starting state 1\n",
      "1 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0\n",
      "\n",
      "greedy traversal for starting state 2\n",
      "2 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0\n",
      "\n",
      "greedy traversal for starting state 3\n",
      "3 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0\n",
      "\n",
      "greedy traversal for starting state 4\n",
      "4 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0 -> 0\n",
      "\n",
      "greedy traversal for starting state 5\n",
      "5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show_traverse():\n",
    "    # Show all the greedy traversals\n",
    "    for i in range(len(q)):\n",
    "        current_state = i\n",
    "        traverse = \"{} -> \".format(current_state)\n",
    "        n_steps = 0\n",
    "        while current_state != 5 and n_steps < 20:\n",
    "            next_state = np.argmax(q[current_state])\n",
    "            current_state = next_state\n",
    "            traverse += \"{} -> \".format(current_state)\n",
    "            n_steps = n_steps + 1\n",
    "        # Cut off final arrow\n",
    "        traverse = traverse[:-4]\n",
    "        print(\"greedy traversal for starting state {}\".format(i))\n",
    "        print(traverse)\n",
    "        print(\"\")\n",
    "    \n",
    "\n",
    "show_traverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_q():\n",
    "    # show all the valid/used transitions\n",
    "    coords = np.array([[2, 2],\n",
    "                       [4, 2],\n",
    "                       [5, 3],\n",
    "                       [4, 4],\n",
    "                       [2, 4],\n",
    "                       [5, 2]])\n",
    "    # invert y axis for display\n",
    "    coords[:, 1] = max(coords[:, 1]) - coords[:, 1]\n",
    "\n",
    "    plt.figure(1, facecolor='w', figsize=(10, 8))\n",
    "    plt.clf()\n",
    "    ax = plt.axes([0., 0., 1., 1.])\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.scatter(coords[:, 0], coords[:, 1], c='r')\n",
    "\n",
    "    start_idx, end_idx = np.where(q > 0)\n",
    "    segments = [[coords[start], coords[stop]]\n",
    "                for start, stop in zip(start_idx, end_idx)]\n",
    "    values = np.array(q[q > 0])\n",
    "    # bump up values for viz\n",
    "    values = values\n",
    "    lc = LineCollection(segments,\n",
    "                        zorder=0, cmap=plt.cm.hot_r)\n",
    "    lc.set_array(values)\n",
    "    ax.add_collection(lc)\n",
    "\n",
    "    verticalalignment = 'top'\n",
    "    horizontalalignment = 'left'\n",
    "    for i in range(len(coords)):\n",
    "        x = coords[i][0]\n",
    "        y = coords[i][1]\n",
    "        name = str(i)\n",
    "        if i == 1:\n",
    "            y = y - .05\n",
    "            x = x + .05\n",
    "        elif i == 3:\n",
    "            y = y - .05\n",
    "            x = x + .05\n",
    "        elif i == 4:\n",
    "            y = y - .05\n",
    "            x = x + .05\n",
    "        else:\n",
    "            y = y + .05\n",
    "            x = x + .05\n",
    "\n",
    "        plt.text(x, y, name, size=10,\n",
    "                 horizontalalignment=horizontalalignment,\n",
    "                 verticalalignment=verticalalignment,\n",
    "                 bbox=dict(facecolor='w',\n",
    "                           edgecolor=plt.cm.spectral(float(len(coords))),\n",
    "                           alpha=.6))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'update_q' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-319a95abf932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         reward = update_q(current_state, next_state, action,\n\u001b[0m\u001b[1;32m     41\u001b[0m                           alpha=alpha, gamma=gamma)\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Goal state has reward 100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'update_q' is not defined"
     ]
    }
   ],
   "source": [
    "gamma = 0.8\n",
    "alpha = 1.\n",
    "n_episodes = 1E3\n",
    "n_states = 6\n",
    "n_actions = 6\n",
    "epsilon = 0.05\n",
    "random_state = np.random.RandomState(1999)\n",
    "for e in range(int(n_episodes)):\n",
    "    states = list(range(n_states))\n",
    "    random_state.shuffle(states)\n",
    "    current_state = states[0]\n",
    "    goal = False\n",
    "    if e % int(n_episodes / 10.) == 0 and e > 0:\n",
    "        pass\n",
    "        # uncomment this to see plots each monitoring\n",
    "        #show_traverse()\n",
    "        #show_q()\n",
    "    while not goal:\n",
    "        # epsilon greedy\n",
    "        valid_moves = r[current_state] >= 0\n",
    "        if random_state.rand() < epsilon:\n",
    "            actions = np.array(list(range(n_actions)))\n",
    "            actions = actions[valid_moves == True]\n",
    "            if type(actions) is int:\n",
    "                actions = [actions]\n",
    "            random_state.shuffle(actions)\n",
    "            action = actions[0]\n",
    "            next_state = action\n",
    "        else:\n",
    "            if np.sum(q[current_state]) > 0:\n",
    "                action = np.argmax(q[current_state])\n",
    "            else:\n",
    "                # Don't allow invalid moves at the start\n",
    "                # Just take a random move\n",
    "                actions = np.array(list(range(n_actions)))\n",
    "                actions = actions[valid_moves == True]\n",
    "                random_state.shuffle(actions)\n",
    "                action = actions[0]\n",
    "            next_state = action\n",
    "        reward = update_q(current_state, next_state, action,\n",
    "                          alpha=alpha, gamma=gamma)\n",
    "        # Goal state has reward 100\n",
    "        if reward > 1:\n",
    "            goal = True\n",
    "        current_state = next_state\n",
    "\n",
    "print(q)\n",
    "show_traverse()\n",
    "show_q()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
